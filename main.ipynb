{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count Surfers in the Water\n",
    "### Description\n",
    "\n",
    "This project is subset of https://github.com/oownus/surfcam/tree/master/surfy\n",
    "\n",
    "This project is to count how many surfers in the water\n",
    "So you know the surfer traffic in the water.\n",
    "\n",
    "A typical good sample image as follows: (You can see 3 people are in the water)\n",
    "\n",
    "In humen brain, it is very easy to count them. Unfortunately, computers need special instructions to do this task\n",
    "\n",
    "<img src=\"./Images/SampleImages_001.png\" width=\"600\" align=\"left\" />\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick Demo\n",
    "https://youtu.be/v-3v6lRVo_Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goal\n",
    "My goal is to let the software automatically count how many people are in the water given series of images (video), this project is to count how many surfers are in the water\n",
    "\n",
    "### File Structure\n",
    "\n",
    "/Images - contains sample images\n",
    "\n",
    "/Video - contains test videos\n",
    "\n",
    "main.ipynb - includes all the instructions\n",
    "\n",
    "\n",
    "### Various conditions\n",
    "\n",
    "Wish there are only good days for beach day. But, unfortunately there are many different weather/environment conditions we need to take care!\n",
    "\n",
    "Condition | Image\n",
    "------------ | -------------\n",
    "Fog |\t<img src=\"./Images/Conditions_Fog.png\" width=\"500\" align=\"left\" />\n",
    "Birds |\t<img src=\"./Images/Conditions_Birds.png\" width=\"500\" align=\"left\" />\n",
    "Dark |\t<img src=\"./Images/Conditions_Dark.png\" width=\"500\" align=\"left\" />\n",
    "Poor Image |\t<img src=\"./Images/Conditions_PoorImageQuality.png\" width=\"500\" align=\"left\" />\n",
    "\n",
    "### Current constraints\n",
    "- Region of interst (ROI) is hardcoded\n",
    "- Need to filter out tree leafs / birds\n",
    "- Cannot find surfers in between the tree leafs\n",
    "- Parameters can be optimized further to increase accuracy\n",
    "- Need to consider dynamic environment changes (weather, light value)\n",
    "\n",
    "### Future possible improvement ideas\n",
    "- Send surfer count to server for data collection\n",
    "- Help lifeguard to monitor people to save lifes\n",
    "\n",
    "### Proejct Pipeline\n",
    "- Get video feed\n",
    "- Set image to gray scale to reduce dimension (color channel)\n",
    "- Set ROI\n",
    "- Apply Gaussian filter to reduce image noise\n",
    "- Masked the image using low/high threshhold value\n",
    "- Find contours. Count countours ultimately will be the number of surfers\n",
    "- Draw contours on the image\n",
    "- Add count text on the image\n",
    "- Display\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Complete code\n",
    "Below is complete code, I will explain each function one by one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "###############################Settings#################################\n",
    "#Blur\n",
    "GAUSSIAN_KERNEL_SIZE = 7 #odd number only\n",
    "#Gray Thresh\n",
    "GRAY_THRESH_LOW = 0\n",
    "GRAY_MASK_THRESH_HIGH = 90\n",
    "#Text\n",
    "ORG = (50,50)\n",
    "FONT = cv2.FONT_HERSHEY_SIMPLEX\n",
    "FONT_SCALE = 1.0\n",
    "FONT_COLOR = (0, 255, 0)\n",
    "#Prv frame\n",
    "MIN_FRAME_COUNT = 7\n",
    "########################################################################\n",
    "#Below variables are used to get previous frame's info\n",
    "cur_frame_count = 0\n",
    "prv_surfer_count = 0\n",
    "out_surfer_count = 0\n",
    "\n",
    "def convert_to_gray(img):\n",
    "    return cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "def region_of_interest(img):\n",
    "    #hard coded since camera angle doesn't change\n",
    "    vertices = np.int32([[240,300],[1053,305],[1211,420],[180,420]])\n",
    "    \n",
    "    img = cv2.polylines(img, np.int32([vertices]), True,(0,0,0),0)\n",
    "    mask = np.zeros_like(img)\n",
    "    \n",
    "    cv2.fillPoly(mask, np.int32([vertices]), 255)\n",
    "    \n",
    "    inverted_mask = cv2.bitwise_not(mask)\n",
    "    \n",
    "    masked_image = cv2.bitwise_or(img, inverted_mask)\n",
    "\n",
    "    return masked_image\n",
    "\n",
    "def gaussian_blur(img,kernel_size):\n",
    "    return cv2.GaussianBlur(img,(kernel_size,kernel_size),0)\n",
    "\n",
    "def masking_img(img, low,high):\n",
    "    return cv2.inRange(img, low,high)\n",
    "\n",
    "def add_count(img, cur_surfer_count):\n",
    "    global cur_frame_count\n",
    "    global prv_surfer_count\n",
    "    global out_surfer_count\n",
    "    if prv_surfer_count == cur_surfer_count:\n",
    "        cur_frame_count +=1\n",
    "        if cur_frame_count == MIN_FRAME_COUNT:\n",
    "            out_surfer_count = prv_surfer_count\n",
    "            cur_frame_count = 0\n",
    "    else:\n",
    "        cur_frame_count = 0\n",
    "        prv_surfer_count = cur_surfer_count\n",
    "        \n",
    "    out_text = 'Number of surfers: '+ str(out_surfer_count)\n",
    "       \n",
    "    cv2.putText(img, out_text, ORG, FONT , FONT_SCALE , FONT_COLOR, lineType=cv2.LINE_AA) \n",
    "    \n",
    "    return img\n",
    "def find_contours(original_img, masked_img):\n",
    "    #arg(threshhold, max, type(0))\n",
    "    ret, thresh = cv2.threshold(masked_img, 127,255,0)\n",
    "\n",
    "    contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    return cv2.drawContours(original_img, contours, -1, (0,255,0), 3), str(len(contours))\n",
    "        \n",
    "\n",
    "def find_surfer(img):    \n",
    "    gray_img = convert_to_gray(img)\n",
    "\n",
    "    ROI_img = region_of_interest(gray_img)\n",
    "\n",
    "    gaussian_img = gaussian_blur(ROI_img,GAUSSIAN_KERNEL_SIZE)\n",
    "\n",
    "    masked_img = masking_img(gaussian_img,GRAY_THRESH_LOW,GRAY_MASK_THRESH_HIGH)\n",
    "\n",
    "    contoured_img,cur_surfer_count = find_contours(img, masked_img)\n",
    "\n",
    "    \n",
    "    add_count_img = add_count(contoured_img, cur_surfer_count)\n",
    "        \n",
    "    return add_count_img\n",
    "\n",
    "cap = cv2.VideoCapture(\"./Videos/SampleVideo01.mp4\") #change path\n",
    "\n",
    "while (cap.isOpened()):\n",
    "    ret,img = cap.read()\n",
    "    img = find_surfer(img)\n",
    "    cv2.imshow('img',img)\n",
    "    k = cv2.waitKey(30)& 0xff\n",
    "    if k ==ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Each function explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### covert_to_gray\n",
    "It is good idea to reduce color channels to 3 to 1 if necessary.\n",
    "\n",
    "It takes less processing power to compute since it is 1 dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_gray(img):\n",
    "    return cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original | Gray\n",
    "------------ | -------------\n",
    "<img src=\"./Images/SampleImages_001.png\" width=\"500\" align=\"left\" /> |\t<img src=\"./Images/Gray_Image.png\" width=\"500\" align=\"left\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Region of interest (ROI)\n",
    "\n",
    "There are only certain area's I am interested in the image. By setting ROI, it will certainly increase the accuracy as well.\n",
    "\n",
    "Currently, ROI coordinates are hard coded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def region_of_interest(img):\n",
    "    #hard coded since camera angle doesn't change\n",
    "    vertices = np.int32([[240,300],[1053,305],[1211,420],[180,420]])\n",
    "    \n",
    "    img = cv2.polylines(img, np.int32([vertices]), True,(0,0,0),0)\n",
    "    mask = np.zeros_like(img)\n",
    "    \n",
    "    cv2.fillPoly(mask, np.int32([vertices]), 255)\n",
    "    \n",
    "    inverted_mask = cv2.bitwise_not(mask)\n",
    "    \n",
    "    masked_image = cv2.bitwise_or(img, inverted_mask)\n",
    "\n",
    "    return masked_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gray | ROI\n",
    "------------ | -------------\n",
    "<img src=\"./Images/Gray_Image.png\" width=\"500\" align=\"left\" />|\t<img src=\"./Images/ROI_Image.png\" width=\"500\" align=\"left\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gaussian_Blur\n",
    "\n",
    "In order to reduce the noise, I choose to use Gaussian blur. By applying blur, it will smoothen our noises so the noise will blend in.\n",
    "\n",
    "gaussian_blur function takes kernel value as an arg. By increasing this value, you will apply the blur more aggressively.\n",
    "\n",
    "You might not tell too much of difference from the sample images below. But, bluring is one of the most useful tool in general to reduce the noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_blur(img,kernel_size):\n",
    "    return cv2.GaussianBlur(img,(kernel_size,kernel_size),0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ROI | Blur\n",
    "------------ | -------------\n",
    "<img src=\"./Images/ROI_Image.png\" width=\"500\" align=\"left\" />|\t<img src=\"./Images/Gaussian_Image.png\" width=\"500\" align=\"left\" />\n",
    "\n",
    "Better example I found on web:\n",
    "\n",
    "<img src=\"./Images/gaussian-blur-web.jpg\" width=\"500\" />\n",
    "\n",
    "image source:https://www.coreldraw.com/en/pages/gaussian-blur/\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Masking\n",
    "\n",
    "User need to set a low and a high threshhold to filter out what we want to see.\n",
    "\n",
    "Forntunately, surfers in the image appear to be small black dot or points which means low values (brighter or close to white means high in value). So, from 0 ~ 90 range can find what I want in our case.\n",
    "\n",
    "After mask is applied, I can see that those white dots are points of the surfers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def masking_img(img, low,high):\n",
    "    return cv2.inRange(img, low,high)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Blur | Mask\n",
    "------------ | -------------\n",
    "<img src=\"./Images/Gaussian_Image.png\" width=\"500\" align=\"left\" />|\t<img src=\"./Images/Masked_Image.png\" width=\"500\" align=\"left\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Contours\n",
    "Now that we have masked image with only surfers in white dots, we can use contour function in CV2\n",
    "\n",
    "Even though white points on the masked image appear to be just dots but it is actually a series of pixel values if you look closely.\n",
    "\n",
    "Computer doesn't know this, if we don't give an instruction, computer might think each pixel is an object.\n",
    "\n",
    "By use contour function in CV2, we can tell the computer that some of the pixels in the list are belong to each other.\n",
    "\n",
    "Below functionwill take original_img and masked_img as args\n",
    "\n",
    "masked_img is to find the thresh hold of the contour value.\n",
    "\n",
    "original_img is to draw the findings.\n",
    "\n",
    "Please note contours variable will contain information of the contour found from the masked_img.\n",
    "\n",
    "By taking length of this variable will give you number of surfers!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_contours(original_img, masked_img):\n",
    "    #arg(threshhold, max, type(0))\n",
    "    ret, thresh = cv2.threshold(masked_img, 127,255,0)\n",
    "\n",
    "    contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    return cv2.drawContours(original_img, contours, -1, (0,255,0), 3), str(len(contours))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mask | Contour and Original combined\n",
    "------------ | -------------\n",
    "<img src=\"./Images/Masked_Image.png\" width=\"500\" align=\"left\" />|\t<img src=\"./Images/Final_Image.png\" width=\"500\" align=\"left\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you just need to put text on the image using cv2.putText as your will!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
